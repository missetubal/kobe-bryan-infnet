{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5b3db1-b5a1-4cbf-a331-d9012ab8eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pycaret.classification as pc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c4037-8a99-4196-8f85-ac955d8ad40b",
   "metadata": {},
   "source": [
    "# Configurando MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149a4a41-d9b1-4b7b-ae5a-b7883e5d6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "\n",
    "experiment_name = 'Kobe Bryant Shot Selection'\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e961ff8c-6a44-42f0-a3b4-f007bb7cc80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "columns=['lat', 'lon', 'minutes_remaining', 'period', 'playoffs', 'shot_distance', 'shot_made_flag']\n",
    "train_perc = 0.8\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'PreparacaoDados'):\n",
    "    df_dev = pd.read_parquet('../data/raw/dataset_kobe_dev.parquet')\n",
    "    df_dev = df_dev.dropna()\n",
    "    df_dev = df_dev[columns].copy()\n",
    "    \n",
    "    df_dev.to_parquet(\"../data/data_filtered.parquet\")\n",
    "    \n",
    "    \n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(df_dev[['lat', 'lon', 'minutes_remaining', 'period', 'playoffs', 'shot_distance']],\n",
    "                                                    df_dev['shot_made_flag'],                                                \n",
    "                                                    train_size=train_perc,\n",
    "                                                    stratify=df_dev['shot_made_flag'])    \n",
    "    xtrain['shot_made_flag'] = ytrain\n",
    "    xtest['shot_made_flag'] = ytest\n",
    "    xtrain.to_parquet('../data/base_train.parquet')\n",
    "    xtest.to_parquet('../data/base_test.parquet')\n",
    "\n",
    "    mlflow.log_params({\n",
    "        'perc-teste': 1-train_perc,\n",
    "        'colunas-selecionadas': columns\n",
    "    })\n",
    "    mlflow.log_metrics({\n",
    "        'qtd_linhas_treino': xtrain.shape[0],\n",
    "        'qtd_linhas_teste': xtest.shape[0],\n",
    "    })\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_perc = 0.8\n",
    "# data_cols = [\"lat\", \"lon\", \"minutes_remaining\", \"period\", \"playoffs\", \"shot_distance\", 'shot_made_flag']\n",
    "\n",
    "\n",
    "# with mlflow.start_run(experiment_id=experiment_id, run_name = 'PreparacaoDados'):\n",
    "#     df_dev = pd.read_parquet('../data/raw/dataset_kobe_dev.parquet')\n",
    "#     df_dev = df_dev.dropna(subset=[\"lat\", \"lon\", \"minutes_remaining\", \"period\", \"playoffs\", \"shot_distance\"], inplace=True)\n",
    "#     mlflow.log_metric('dimensao_dataset_filtrado', len(df_dev))\n",
    "    \n",
    "    \n",
    "#     le = LabelEncoder()\n",
    "#     df_dev[\"period\"] = le.fit_transform(df_dev[\"period\"])\n",
    "#     df_dev[\"playoffs\"] = le.fit_transform(df_dev[\"playoffs\"])\n",
    "#     mlflow.log_metric(\"categorias_period\", len(le.classes_))\n",
    "#     mlflow.log_metric(\"categorias_playoffs\", len(le.classes_))\n",
    "\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(df_dev[[\"lat\", \"lon\", \"minutes_remaining\", \"shot_distance\"]])\n",
    "  \n",
    "#     df_dev[\"lat_norm\"] = scaler.transform(df_dev[[\"lat\"]])[:, 0]\n",
    "#     df_dev[\"lon_norm\"] = scaler.transform(df_dev[[\"lon\"]])[:, 0]\n",
    "#     df_dev[\"minutes_remaining_norm\"] = scaler.transform(df_dev[[\"minutes_remaining\"]])[:, 0]\n",
    "#     df_dev[\"shot_distance_norm\"] = scaler.transform(df_dev[[\"shot_distance\"]])[:, 0]\n",
    "\n",
    "\n",
    "#     df_dev.drop(columns=[\"lat\", \"lon\", \"minutes_remaining\", \"shot_distance\"], inplace=True)\n",
    "#     df_dev = df_dev[[\"period\", \"playoffs\", \"lat_norm\", \"lon_norm\", \"minutes_remaining_norm\", \"shot_distance_norm\", \"shot_made_flag\"]]\n",
    "    \n",
    "#     df_dev.to_parquet(\"../data/data_filtered.parquet\")\n",
    "\n",
    "#     mlflow.log_metric(\"dimensao_dataset_final\", len(df_dev))\n",
    "\n",
    "#     #Separação dos dados em treino e teste\n",
    "#     X = df_dev[[\"period\", \"playoffs\", \"lat_norm\", \"lon_norm\", \"minutes_remaining_norm\", \"shot_distance_norm\"]]\n",
    "#     y = df_dev[\"shot_made_flag\"]\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=train_perc, stratify=y)\n",
    "\n",
    "#     # Saving data sets\n",
    "#     X_train.to_parquet(\"/data/processed/base_train.parquet\")\n",
    "#     X_test.to_parquet(\"/data/processed/base_test.parquet\")\n",
    "#     y_train.to_parquet(\"/data/processed/base_train_target.parquet\")\n",
    "#     y_test.to_parquet(\"/data/processed/base_test_target.parquet\")\n",
    "\n",
    "#     # Log metrics\n",
    "#     mlflow.log_param(\"porcentagem_teste\", train_perc)\n",
    "#     mlflow.log_metric(\"dimensao_treino\", len(X_train))\n",
    "#     mlflow.log_metric(\"dimensao_teste\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6044a117-1b54-4541-bf3e-f0b2afd03a81",
   "metadata": {},
   "source": [
    "# Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec107f9-e5cc-4056-b65d-f279850d2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "\n",
    "def plot_parameter_validation_curve(X, Y, param_name, grid_search,\n",
    "                                    model, model_name, scoring,\n",
    "                                    logx):\n",
    "    print('Parameter:', param_name)\n",
    "    print('GridSearch:', grid_search[param_name])\n",
    "    print('Scoring:', scoring)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    train_scores, test_scores = validation_curve(model,\n",
    "                                                 X = X, \n",
    "                                                 y = Y, \n",
    "                                                 param_name=param_name, \n",
    "                                                 param_range= grid_search[param_name],\n",
    "                                                 scoring=scoring,\n",
    "                                                 cv=10,\n",
    "                                                 n_jobs=-1)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.title(\"Curva Validação Modelo \" + model_name)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score (\"+scoring+\")\")\n",
    "    if logx:\n",
    "        plt.semilogx(grid_search[param_name], train_scores_mean,'-o', label=\"Treino\",\n",
    "                     color=\"darkorange\", lw=2)\n",
    "        plt.semilogx(grid_search[param_name], test_scores_mean,'-o', label=\"Validação-Cruzada\",\n",
    "                     color=\"navy\", lw=2)\n",
    "    else:\n",
    "        plt.plot(grid_search[param_name], train_scores_mean,'-o', label=\"Treino\",\n",
    "                     color=\"darkorange\", lw=2)\n",
    "        plt.plot(grid_search[param_name], test_scores_mean,'-o', label=\"Validação-Cruzada\",\n",
    "                 color=\"navy\", lw=2)\n",
    "    plt.fill_between(grid_search[param_name], train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=2)\n",
    "    plt.fill_between(grid_search[param_name], test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=2)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12233372-beae-4890-9462-c9b18446fc07",
   "metadata": {},
   "source": [
    "# Validação Cruzada de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8370002-34d7-4465-a962-628a90d9d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "\n",
    "def plot_parameter_validation_curve(X, Y, param_name, grid_search,\n",
    "                                    model, model_name, scoring,\n",
    "                                    logx):\n",
    "    print('Parameter:', param_name)\n",
    "    print('GridSearch:', grid_search[param_name])\n",
    "    print('Scoring:', scoring)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    train_scores, test_scores = validation_curve(model,\n",
    "                                                 X = X, \n",
    "                                                 y = Y, \n",
    "                                                 param_name=param_name, \n",
    "                                                 param_range= grid_search[param_name],\n",
    "                                                 scoring=scoring,\n",
    "                                                 cv=10,\n",
    "                                                 n_jobs=-1)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.title(\"Curva Validação Modelo \" + model_name)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score (\"+scoring+\")\")\n",
    "    if logx:\n",
    "        plt.semilogx(grid_search[param_name], train_scores_mean,'-o', label=\"Treino\",\n",
    "                     color=\"darkorange\", lw=2)\n",
    "        plt.semilogx(grid_search[param_name], test_scores_mean,'-o', label=\"Validação-Cruzada\",\n",
    "                     color=\"navy\", lw=2)\n",
    "    else:\n",
    "        plt.plot(grid_search[param_name], train_scores_mean,'-o', label=\"Treino\",\n",
    "                     color=\"darkorange\", lw=2)\n",
    "        plt.plot(grid_search[param_name], test_scores_mean,'-o', label=\"Validação-Cruzada\",\n",
    "                 color=\"navy\", lw=2)\n",
    "    plt.fill_between(grid_search[param_name], train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=2)\n",
    "    plt.fill_between(grid_search[param_name], test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=2)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e011af00-c755-4ce7-b34b-27521dcca55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3359b_row8_col1, #T_3359b_row12_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3359b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3359b_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_3359b_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3359b_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_3359b_row0_col1\" class=\"data row0 col1\" >6817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3359b_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_3359b_row1_col1\" class=\"data row1 col1\" >shot_made_flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3359b_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_3359b_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3359b_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_3359b_row3_col1\" class=\"data row3 col1\" >(20285, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3359b_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_3359b_row4_col1\" class=\"data row4 col1\" >(20285, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3359b_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_3359b_row5_col1\" class=\"data row5 col1\" >(16228, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3359b_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_3359b_row6_col1\" class=\"data row6 col1\" >(4057, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3359b_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_3359b_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3359b_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_3359b_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3359b_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_3359b_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_3359b_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_3359b_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_3359b_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_3359b_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_3359b_row12_col0\" class=\"data row12 col0\" >Normalize</td>\n",
       "      <td id=\"T_3359b_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_3359b_row13_col0\" class=\"data row13 col0\" >Normalize method</td>\n",
       "      <td id=\"T_3359b_row13_col1\" class=\"data row13 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_3359b_row14_col0\" class=\"data row14 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_3359b_row14_col1\" class=\"data row14 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_3359b_row15_col0\" class=\"data row15 col0\" >Fold Number</td>\n",
       "      <td id=\"T_3359b_row15_col1\" class=\"data row15 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_3359b_row16_col0\" class=\"data row16 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_3359b_row16_col1\" class=\"data row16 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_3359b_row17_col0\" class=\"data row17 col0\" >Use GPU</td>\n",
       "      <td id=\"T_3359b_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_3359b_row18_col0\" class=\"data row18 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_3359b_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_3359b_row19_col0\" class=\"data row19 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_3359b_row19_col1\" class=\"data row19 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3359b_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_3359b_row20_col0\" class=\"data row20 col0\" >USI</td>\n",
       "      <td id=\"T_3359b_row20_col1\" class=\"data row20 col1\" >7488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x202e0751290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_791d8 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_791d8_row0_col0, #T_791d8_row0_col1, #T_791d8_row0_col2, #T_791d8_row0_col4, #T_791d8_row0_col6, #T_791d8_row0_col7, #T_791d8_row1_col0, #T_791d8_row1_col3, #T_791d8_row1_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_791d8_row0_col3, #T_791d8_row0_col5, #T_791d8_row1_col1, #T_791d8_row1_col2, #T_791d8_row1_col4, #T_791d8_row1_col6, #T_791d8_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_791d8_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_791d8_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_791d8\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_791d8_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_791d8_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_791d8_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_791d8_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_791d8_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_791d8_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_791d8_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_791d8_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_791d8_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_791d8_level0_row0\" class=\"row_heading level0 row0\" >dt</th>\n",
       "      <td id=\"T_791d8_row0_col0\" class=\"data row0 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_791d8_row0_col1\" class=\"data row0 col1\" >0.5312</td>\n",
       "      <td id=\"T_791d8_row0_col2\" class=\"data row0 col2\" >0.5120</td>\n",
       "      <td id=\"T_791d8_row0_col3\" class=\"data row0 col3\" >0.5753</td>\n",
       "      <td id=\"T_791d8_row0_col4\" class=\"data row0 col4\" >0.5082</td>\n",
       "      <td id=\"T_791d8_row0_col5\" class=\"data row0 col5\" >0.5395</td>\n",
       "      <td id=\"T_791d8_row0_col6\" class=\"data row0 col6\" >0.0660</td>\n",
       "      <td id=\"T_791d8_row0_col7\" class=\"data row0 col7\" >0.0664</td>\n",
       "      <td id=\"T_791d8_row0_col8\" class=\"data row0 col8\" >0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_791d8_level0_row1\" class=\"row_heading level0 row1\" >lr</th>\n",
       "      <td id=\"T_791d8_row1_col0\" class=\"data row1 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_791d8_row1_col1\" class=\"data row1 col1\" >0.5746</td>\n",
       "      <td id=\"T_791d8_row1_col2\" class=\"data row1 col2\" >0.5973</td>\n",
       "      <td id=\"T_791d8_row1_col3\" class=\"data row1 col3\" >0.4841</td>\n",
       "      <td id=\"T_791d8_row1_col4\" class=\"data row1 col4\" >0.5634</td>\n",
       "      <td id=\"T_791d8_row1_col5\" class=\"data row1 col5\" >0.5207</td>\n",
       "      <td id=\"T_791d8_row1_col6\" class=\"data row1 col6\" >0.1423</td>\n",
       "      <td id=\"T_791d8_row1_col7\" class=\"data row1 col7\" >0.1436</td>\n",
       "      <td id=\"T_791d8_row1_col8\" class=\"data row1 col8\" >0.0110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x202d9814e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Aplicando  lr\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "plot_model() got an unexpected keyword argument 'use_train_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m plot_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=> Aplicando \u001b[39m\u001b[38;5;124m'\u001b[39m, plot_type)\n\u001b[1;32m---> 24\u001b[0m     artifact \u001b[38;5;241m=\u001b[39m pc\u001b[38;5;241m.\u001b[39mplot_model(list_models[\u001b[38;5;241m0\u001b[39m], plot\u001b[38;5;241m=\u001b[39mplot_type, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, use_train_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_artifact(artifact)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# REGRESSAO\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pycaret\\utils\\generic.py:965\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m globals_d[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[1;32m--> 965\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: plot_model() got an unexpected keyword argument 'use_train_data'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "\n",
    "registered_model_name = 'model_kobe'\n",
    "nexamples = 5\n",
    "model_version = -1\n",
    "models = ['lr','dt']\n",
    "\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'Treinamento'):\n",
    "  \n",
    "    exp = pc.setup(\n",
    "        data=xtrain,\n",
    "        target = 'shot_made_flag',\n",
    "        fold_strategy = 'stratifiedkfold',\n",
    "        test_data = xtest,\n",
    "        normalize=True,\n",
    "        log_experiment = False\n",
    "    )\n",
    "    list_models = pc.compare_models(['lr','dt'], n_select=2, sort='f1')\n",
    "\n",
    "    for plot_type in ['lr','dt']:\n",
    "        print('=> Aplicando ', plot_type)\n",
    "        artifact = pc.plot_model(list_models[0], plot=plot_type, save=True, use_train_data=False)\n",
    "        mlflow.log_artifact(artifact)\n",
    "\n",
    "\n",
    "    # REGRESSAO\n",
    "    exp.plot_model(list_models[0], plot='vc', save = True)\n",
    "    yhat_test = exp.predict_model(list_models[0])\n",
    "    plot_parameter_validation_curve(xtrain.drop('shot_made_flag', axis=1), ytrain, 'C', {'C': [0.001, 0.01, 0.1, 1, 10]},\n",
    "                                        list_models[0], 'Regressão Logística', 'f1', logx=False)\n",
    "    plt.savefig('lr_validation_curve.png')\n",
    "    mlflow.log_artifact('lr_validation_curve.png')\n",
    "    # os.remove('lr_validation_curve.png')\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        'lr_log_loss': log_loss(yhat_test.target, yhat_test.prediction_label),\n",
    "        'lr_f1': f1_score(yhat_test.target, yhat_test.prediction_label),\n",
    "    })\n",
    "    \n",
    "    # ARVORE\n",
    "    yhat_test = exp.predict_model(list_models[1])\n",
    "    plot_parameter_validation_curve(xtrain.drop('shot_made_flag', axis=1), ytrain, 'max_depth', {'max_depth': [2, 3, 4, 5, 6, 7, 8]},\n",
    "                                    list_models[1], 'Árvore Decisão', 'f1', logx=False)\n",
    "    plt.savefig('dt_validation_curve.png')\n",
    "    mlflow.log_artifact('dt_validation_curve.png')\n",
    "    # os.remove('dt_validation_curve.png')\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        'dt_log_loss': log_loss(yhat_test.target, yhat_test.prediction_label),\n",
    "        'dt_f1': f1_score(yhat_test.target, yhat_test.prediction_label),\n",
    "    })\n",
    "    \n",
    "     # FINALIZACAO MELHOR MODELO\n",
    "    tune_model = exp.tune_model(list_models[0],\n",
    "                                optimize = 'f1',\n",
    "                                search_library = 'scikit-learn',\n",
    "                                search_algorithm = 'random',\n",
    "                                n_iter = 4)\n",
    "    yhat_test = exp.predict_model(tune_model, raw_score=True)\n",
    "\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        'final_model_log_loss': log_loss(yhat_test.target, yhat_test.prediction_label),\n",
    "        'final_model_f1': f1_score(yhat_test.target, yhat_test.prediction_label),\n",
    "    })\n",
    "    yhat_test.to_parquet('../data/processed/prediction_test.parquet')\n",
    "    mlflow.log_artifact('../data/processed/prediction_test.parquet')\n",
    "    \n",
    "    final_model = exp.finalize_model(tune_model)\n",
    "\n",
    "    artifact = pc.plot_model(final_model, plot=plot_type, save=True)\n",
    "    mlflow.log_artifact(artifact)\n",
    "    \n",
    "    # EXPORTACAO PARA LOG E REGISTRO DO MODELO\n",
    "    exp.save_model(final_model, f'./{registered_model_name}') \n",
    "    # Carrega novamente o pipeline + bestmodel\n",
    "    model_pipe = exp.load_model(f'./{registered_model_name}')\n",
    "    # Assinatura do Modelo Inferida pelo MLFlow\n",
    "    model_features = list(xtrain.drop('shot_made_flag', axis=1).columns)\n",
    "    inf_signature = infer_signature(xtrain[model_features], \n",
    "                                    model_pipe.predict_proba(xtrain.drop('target', axis=1)))\n",
    "    # Exemplo de entrada para o MLmodel\n",
    "    input_example = {x: xtrain[x].values[:nexamples] for x in model_features}\n",
    "    # Log do pipeline de modelagem do sklearn e registrar como uma nova versao\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model_pipe,\n",
    "        artifact_path=\"sklearn-model\",\n",
    "        registered_model_name=registered_model_name,\n",
    "        signature = inf_signature,\n",
    "        input_example = input_example,\n",
    "        pyfunc_predict_fn='predict_proba'\n",
    "    )\n",
    "    # Criacao do cliente do servico MLFlow e atualizacao versao modelo\n",
    "    client = MlflowClient()\n",
    "    if model_version == -1:\n",
    "        model_version = client.get_latest_versions(registered_model_name)[-1].version\n",
    "    # Registrar o modelo como staging\n",
    "    client.set_registered_model_alias(\n",
    "        name    = registered_model_name, \n",
    "        alias   = \"staging\", \n",
    "        version = model_version\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447fb4b0-81db-45a5-9acf-a4c02e410140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
