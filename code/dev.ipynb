{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d5b3db1-b5a1-4cbf-a331-d9012ab8eee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pycaret.classification as pc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow.tracking import MlflowClient\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c4037-8a99-4196-8f85-ac955d8ad40b",
   "metadata": {},
   "source": [
    "# Configurando MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149a4a41-d9b1-4b7b-ae5a-b7883e5d6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"sqlite:///mlruns.db\")\n",
    "\n",
    "experiment_name = 'Kobe Bryant Shot Selection'\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "if experiment is None:\n",
    "    experiment_id = mlflow.create_experiment(experiment_name)\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e961ff8c-6a44-42f0-a3b4-f007bb7cc80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/14 21:48:49 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial warning can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|none|n|0: for no warning or exception\n",
      "    - warn|w|warning|1: for a printed warning\n",
      "    - error|e|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "columns=['lat', 'lon', 'minutes_remaining', 'period', 'playoffs', 'shot_distance', 'shot_made_flag']\n",
    "train_perc = 0.8\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'PreparacaoDados'):\n",
    "    df_dev = pd.read_parquet('../data/raw/dataset_kobe_dev.parquet')\n",
    "    df_dev = df_dev.dropna()\n",
    "    df_dev = df_dev[columns].copy()\n",
    "    \n",
    "    df_dev.to_parquet(\"../data/data_filtered.parquet\")\n",
    "    \n",
    "    \n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(df_dev[['lat', 'lon', 'minutes_remaining', 'period', 'playoffs', 'shot_distance']],\n",
    "                                                    df_dev['shot_made_flag'],                                                \n",
    "                                                    train_size=train_perc,\n",
    "                                                    stratify=df_dev['shot_made_flag'])    \n",
    "    xtrain['shot_made_flag'] = ytrain\n",
    "    xtest['shot_made_flag'] = ytest\n",
    "    xtrain.to_parquet('../data/base_train.parquet')\n",
    "    xtest.to_parquet('../data/base_test.parquet')\n",
    "\n",
    "    mlflow.log_params({\n",
    "        'perc-teste': 1-train_perc,\n",
    "        'colunas-selecionadas': columns\n",
    "    })\n",
    "    mlflow.log_metrics({\n",
    "        'qtd_linhas_treino': xtrain.shape[0],\n",
    "        'qtd_linhas_teste': xtest.shape[0],\n",
    "    })\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_perc = 0.8\n",
    "# data_cols = [\"lat\", \"lon\", \"minutes_remaining\", \"period\", \"playoffs\", \"shot_distance\", 'shot_made_flag']\n",
    "\n",
    "\n",
    "# with mlflow.start_run(experiment_id=experiment_id, run_name = 'PreparacaoDados'):\n",
    "#     df_dev = pd.read_parquet('../data/raw/dataset_kobe_dev.parquet')\n",
    "#     df_dev = df_dev.dropna(subset=[\"lat\", \"lon\", \"minutes_remaining\", \"period\", \"playoffs\", \"shot_distance\"], inplace=True)\n",
    "#     mlflow.log_metric('dimensao_dataset_filtrado', len(df_dev))\n",
    "    \n",
    "    \n",
    "#     le = LabelEncoder()\n",
    "#     df_dev[\"period\"] = le.fit_transform(df_dev[\"period\"])\n",
    "#     df_dev[\"playoffs\"] = le.fit_transform(df_dev[\"playoffs\"])\n",
    "#     mlflow.log_metric(\"categorias_period\", len(le.classes_))\n",
    "#     mlflow.log_metric(\"categorias_playoffs\", len(le.classes_))\n",
    "\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(df_dev[[\"lat\", \"lon\", \"minutes_remaining\", \"shot_distance\"]])\n",
    "  \n",
    "#     df_dev[\"lat_norm\"] = scaler.transform(df_dev[[\"lat\"]])[:, 0]\n",
    "#     df_dev[\"lon_norm\"] = scaler.transform(df_dev[[\"lon\"]])[:, 0]\n",
    "#     df_dev[\"minutes_remaining_norm\"] = scaler.transform(df_dev[[\"minutes_remaining\"]])[:, 0]\n",
    "#     df_dev[\"shot_distance_norm\"] = scaler.transform(df_dev[[\"shot_distance\"]])[:, 0]\n",
    "\n",
    "\n",
    "#     df_dev.drop(columns=[\"lat\", \"lon\", \"minutes_remaining\", \"shot_distance\"], inplace=True)\n",
    "#     df_dev = df_dev[[\"period\", \"playoffs\", \"lat_norm\", \"lon_norm\", \"minutes_remaining_norm\", \"shot_distance_norm\", \"shot_made_flag\"]]\n",
    "    \n",
    "#     df_dev.to_parquet(\"../data/data_filtered.parquet\")\n",
    "\n",
    "#     mlflow.log_metric(\"dimensao_dataset_final\", len(df_dev))\n",
    "\n",
    "#     #Separação dos dados em treino e teste\n",
    "#     X = df_dev[[\"period\", \"playoffs\", \"lat_norm\", \"lon_norm\", \"minutes_remaining_norm\", \"shot_distance_norm\"]]\n",
    "#     y = df_dev[\"shot_made_flag\"]\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=train_perc, stratify=y)\n",
    "\n",
    "#     # Saving data sets\n",
    "#     X_train.to_parquet(\"/data/processed/base_train.parquet\")\n",
    "#     X_test.to_parquet(\"/data/processed/base_test.parquet\")\n",
    "#     y_train.to_parquet(\"/data/processed/base_train_target.parquet\")\n",
    "#     y_test.to_parquet(\"/data/processed/base_test_target.parquet\")\n",
    "\n",
    "#     # Log metrics\n",
    "#     mlflow.log_param(\"porcentagem_teste\", train_perc)\n",
    "#     mlflow.log_metric(\"dimensao_treino\", len(X_train))\n",
    "#     mlflow.log_metric(\"dimensao_teste\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6044a117-1b54-4541-bf3e-f0b2afd03a81",
   "metadata": {},
   "source": [
    "# Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec107f9-e5cc-4056-b65d-f279850d2dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "\n",
    "def plot_parameter_validation_curve(X, Y, param_name, grid_search,\n",
    "                                    model, model_name, scoring,\n",
    "                                    logx):\n",
    "    print('Parameter:', param_name)\n",
    "    print('GridSearch:', grid_search[param_name])\n",
    "    print('Scoring:', scoring)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    train_scores, test_scores = validation_curve(model,\n",
    "                                                 X = X, \n",
    "                                                 y = Y, \n",
    "                                                 param_name=param_name, \n",
    "                                                 param_range= grid_search[param_name],\n",
    "                                                 scoring=scoring,\n",
    "                                                 cv=10,\n",
    "                                                 n_jobs=-1)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.title(\"Curva Validação Modelo \" + model_name)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score (\"+scoring+\")\")\n",
    "    if logx:\n",
    "        plt.semilogx(grid_search[param_name], train_scores_mean,'-o', label=\"Treino\",\n",
    "                     color=\"darkorange\", lw=2)\n",
    "        plt.semilogx(grid_search[param_name], test_scores_mean,'-o', label=\"Validação-Cruzada\",\n",
    "                     color=\"navy\", lw=2)\n",
    "    else:\n",
    "        plt.plot(grid_search[param_name], train_scores_mean,'-o', label=\"Treino\",\n",
    "                     color=\"darkorange\", lw=2)\n",
    "        plt.plot(grid_search[param_name], test_scores_mean,'-o', label=\"Validação-Cruzada\",\n",
    "                 color=\"navy\", lw=2)\n",
    "    plt.fill_between(grid_search[param_name], train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=2)\n",
    "    plt.fill_between(grid_search[param_name], test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=2)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12233372-beae-4890-9462-c9b18446fc07",
   "metadata": {},
   "source": [
    "# Validação Cruzada de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8370002-34d7-4465-a962-628a90d9d6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "\n",
    "def plot_parameter_validation_curve(X, Y, param_name, grid_search,\n",
    "                                    model, model_name, scoring,\n",
    "                                    logx):\n",
    "    print('Parameter:', param_name)\n",
    "    print('GridSearch:', grid_search[param_name])\n",
    "    print('Scoring:', scoring)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    train_scores, test_scores = validation_curve(model,\n",
    "                                                 X = X, \n",
    "                                                 y = Y, \n",
    "                                                 param_name=param_name, \n",
    "                                                 param_range= grid_search[param_name],\n",
    "                                                 scoring=scoring,\n",
    "                                                 cv=10,\n",
    "                                                 n_jobs=-1)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.title(\"Curva Validação Modelo \" + model_name)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score (\"+scoring+\")\")\n",
    "    if logx:\n",
    "        plt.semilogx(grid_search[param_name], train_scores_mean,'-o', label=\"Treino\",\n",
    "                     color=\"darkorange\", lw=2)\n",
    "        plt.semilogx(grid_search[param_name], test_scores_mean,'-o', label=\"Validação-Cruzada\",\n",
    "                     color=\"navy\", lw=2)\n",
    "    else:\n",
    "        plt.plot(grid_search[param_name], train_scores_mean,'-o', label=\"Treino\",\n",
    "                     color=\"darkorange\", lw=2)\n",
    "        plt.plot(grid_search[param_name], test_scores_mean,'-o', label=\"Validação-Cruzada\",\n",
    "                 color=\"navy\", lw=2)\n",
    "    plt.fill_between(grid_search[param_name], train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                     color=\"darkorange\", lw=2)\n",
    "    plt.fill_between(grid_search[param_name], test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                     color=\"navy\", lw=2)\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid(True)\n",
    "    plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e011af00-c755-4ce7-b34b-27521dcca55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_59e90_row8_col1, #T_59e90_row12_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_59e90\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_59e90_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_59e90_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_59e90_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_59e90_row0_col1\" class=\"data row0 col1\" >2407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_59e90_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_59e90_row1_col1\" class=\"data row1 col1\" >shot_made_flag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_59e90_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_59e90_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_59e90_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_59e90_row3_col1\" class=\"data row3 col1\" >(20285, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_59e90_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_59e90_row4_col1\" class=\"data row4 col1\" >(20285, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_59e90_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_59e90_row5_col1\" class=\"data row5 col1\" >(16228, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_59e90_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_59e90_row6_col1\" class=\"data row6 col1\" >(4057, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_59e90_row7_col0\" class=\"data row7 col0\" >Numeric features</td>\n",
       "      <td id=\"T_59e90_row7_col1\" class=\"data row7 col1\" >6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_59e90_row8_col0\" class=\"data row8 col0\" >Preprocess</td>\n",
       "      <td id=\"T_59e90_row8_col1\" class=\"data row8 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_59e90_row9_col0\" class=\"data row9 col0\" >Imputation type</td>\n",
       "      <td id=\"T_59e90_row9_col1\" class=\"data row9 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_59e90_row10_col0\" class=\"data row10 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_59e90_row10_col1\" class=\"data row10 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_59e90_row11_col0\" class=\"data row11 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_59e90_row11_col1\" class=\"data row11 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_59e90_row12_col0\" class=\"data row12 col0\" >Normalize</td>\n",
       "      <td id=\"T_59e90_row12_col1\" class=\"data row12 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_59e90_row13_col0\" class=\"data row13 col0\" >Normalize method</td>\n",
       "      <td id=\"T_59e90_row13_col1\" class=\"data row13 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_59e90_row14_col0\" class=\"data row14 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_59e90_row14_col1\" class=\"data row14 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_59e90_row15_col0\" class=\"data row15 col0\" >Fold Number</td>\n",
       "      <td id=\"T_59e90_row15_col1\" class=\"data row15 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_59e90_row16_col0\" class=\"data row16 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_59e90_row16_col1\" class=\"data row16 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_59e90_row17_col0\" class=\"data row17 col0\" >Use GPU</td>\n",
       "      <td id=\"T_59e90_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_59e90_row18_col0\" class=\"data row18 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_59e90_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_59e90_row19_col0\" class=\"data row19 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_59e90_row19_col1\" class=\"data row19 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_59e90_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_59e90_row20_col0\" class=\"data row20 col0\" >USI</td>\n",
       "      <td id=\"T_59e90_row20_col1\" class=\"data row20 col1\" >10c9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x18ccbcb46d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_1c5f2 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_1c5f2_row0_col0, #T_1c5f2_row0_col1, #T_1c5f2_row0_col2, #T_1c5f2_row0_col4, #T_1c5f2_row0_col6, #T_1c5f2_row0_col7, #T_1c5f2_row1_col0, #T_1c5f2_row1_col3, #T_1c5f2_row1_col5 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_1c5f2_row0_col3, #T_1c5f2_row0_col5, #T_1c5f2_row1_col1, #T_1c5f2_row1_col2, #T_1c5f2_row1_col4, #T_1c5f2_row1_col6, #T_1c5f2_row1_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_1c5f2_row0_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_1c5f2_row1_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_1c5f2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1c5f2_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_1c5f2_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_1c5f2_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_1c5f2_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_1c5f2_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_1c5f2_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_1c5f2_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_1c5f2_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_1c5f2_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1c5f2_level0_row0\" class=\"row_heading level0 row0\" >dt</th>\n",
       "      <td id=\"T_1c5f2_row0_col0\" class=\"data row0 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_1c5f2_row0_col1\" class=\"data row0 col1\" >0.5378</td>\n",
       "      <td id=\"T_1c5f2_row0_col2\" class=\"data row0 col2\" >0.5221</td>\n",
       "      <td id=\"T_1c5f2_row0_col3\" class=\"data row0 col3\" >0.5789</td>\n",
       "      <td id=\"T_1c5f2_row0_col4\" class=\"data row0 col4\" >0.5141</td>\n",
       "      <td id=\"T_1c5f2_row0_col5\" class=\"data row0 col5\" >0.5445</td>\n",
       "      <td id=\"T_1c5f2_row0_col6\" class=\"data row0 col6\" >0.0788</td>\n",
       "      <td id=\"T_1c5f2_row0_col7\" class=\"data row0 col7\" >0.0794</td>\n",
       "      <td id=\"T_1c5f2_row0_col8\" class=\"data row0 col8\" >0.0150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_1c5f2_level0_row1\" class=\"row_heading level0 row1\" >lr</th>\n",
       "      <td id=\"T_1c5f2_row1_col0\" class=\"data row1 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_1c5f2_row1_col1\" class=\"data row1 col1\" >0.5744</td>\n",
       "      <td id=\"T_1c5f2_row1_col2\" class=\"data row1 col2\" >0.5956</td>\n",
       "      <td id=\"T_1c5f2_row1_col3\" class=\"data row1 col3\" >0.4814</td>\n",
       "      <td id=\"T_1c5f2_row1_col4\" class=\"data row1 col4\" >0.5636</td>\n",
       "      <td id=\"T_1c5f2_row1_col5\" class=\"data row1 col5\" >0.5192</td>\n",
       "      <td id=\"T_1c5f2_row1_col6\" class=\"data row1 col6\" >0.1417</td>\n",
       "      <td id=\"T_1c5f2_row1_col7\" class=\"data row1 col7\" >0.1432</td>\n",
       "      <td id=\"T_1c5f2_row1_col8\" class=\"data row1 col8\" >0.0110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x18cfdb98250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Aplicando  lr\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Plot Not Available. Please see docstring for list of available Plots.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m plot_type \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=> Aplicando \u001b[39m\u001b[38;5;124m'\u001b[39m, plot_type)\n\u001b[1;32m---> 24\u001b[0m     artifact \u001b[38;5;241m=\u001b[39m pc\u001b[38;5;241m.\u001b[39mplot_model(list_models[\u001b[38;5;241m0\u001b[39m], plot\u001b[38;5;241m=\u001b[39mplot_type, save\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mlog_artifact(artifact)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# REGRESSAO\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pycaret\\utils\\generic.py:965\u001b[0m, in \u001b[0;36mcheck_if_global_is_not_none.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m globals_d[name] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n\u001b[1;32m--> 965\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pycaret\\classification\\functional.py:1725\u001b[0m, in \u001b[0;36mplot_model\u001b[1;34m(estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, verbose, display_format)\u001b[0m\n\u001b[0;32m   1611\u001b[0m \u001b[38;5;129m@check_if_global_is_not_none\u001b[39m(\u001b[38;5;28mglobals\u001b[39m(), _CURRENT_EXPERIMENT_DECORATOR_DICT)\n\u001b[0;32m   1612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_model\u001b[39m(\n\u001b[0;32m   1613\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1622\u001b[0m     display_format: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1623\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1625\u001b[0m \u001b[38;5;124;03m    This function analyzes the performance of a trained model on holdout set.\u001b[39;00m\n\u001b[0;32m   1626\u001b[0m \u001b[38;5;124;03m    It may require re-training the model in certain cases.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1722\u001b[0m \n\u001b[0;32m   1723\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1725\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _CURRENT_EXPERIMENT\u001b[38;5;241m.\u001b[39mplot_model(\n\u001b[0;32m   1726\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1727\u001b[0m         plot\u001b[38;5;241m=\u001b[39mplot,\n\u001b[0;32m   1728\u001b[0m         scale\u001b[38;5;241m=\u001b[39mscale,\n\u001b[0;32m   1729\u001b[0m         save\u001b[38;5;241m=\u001b[39msave,\n\u001b[0;32m   1730\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   1731\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   1732\u001b[0m         plot_kwargs\u001b[38;5;241m=\u001b[39mplot_kwargs,\n\u001b[0;32m   1733\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   1734\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1735\u001b[0m         display_format\u001b[38;5;241m=\u001b[39mdisplay_format,\n\u001b[0;32m   1736\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pycaret\\classification\\oop.py:2071\u001b[0m, in \u001b[0;36mClassificationExperiment.plot_model\u001b[1;34m(self, estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, verbose, display_format)\u001b[0m\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_model\u001b[39m(\n\u001b[0;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1959\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1968\u001b[0m     display_format: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1969\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1970\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;124;03m    This function analyzes the performance of a trained model on holdout set.\u001b[39;00m\n\u001b[0;32m   1972\u001b[0m \u001b[38;5;124;03m    It may require re-training the model in certain cases.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \n\u001b[0;32m   2069\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2071\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mplot_model(\n\u001b[0;32m   2072\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   2073\u001b[0m         plot\u001b[38;5;241m=\u001b[39mplot,\n\u001b[0;32m   2074\u001b[0m         scale\u001b[38;5;241m=\u001b[39mscale,\n\u001b[0;32m   2075\u001b[0m         save\u001b[38;5;241m=\u001b[39msave,\n\u001b[0;32m   2076\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   2077\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   2078\u001b[0m         plot_kwargs\u001b[38;5;241m=\u001b[39mplot_kwargs,\n\u001b[0;32m   2079\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   2080\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2081\u001b[0m         display_format\u001b[38;5;241m=\u001b[39mdisplay_format,\n\u001b[0;32m   2082\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\tabular_experiment.py:2045\u001b[0m, in \u001b[0;36m_TabularExperiment.plot_model\u001b[1;34m(self, estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, feature_name, label, verbose, display_format)\u001b[0m\n\u001b[0;32m   1933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_model\u001b[39m(\n\u001b[0;32m   1934\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1935\u001b[0m     estimator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1946\u001b[0m     display_format: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1947\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;124;03m    This function takes a trained model object and returns a plot based on the\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;124;03m    test / hold-out set. The process may require the model to be re-trained in\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2043\u001b[0m \n\u001b[0;32m   2044\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2045\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_model(\n\u001b[0;32m   2046\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   2047\u001b[0m         plot\u001b[38;5;241m=\u001b[39mplot,\n\u001b[0;32m   2048\u001b[0m         scale\u001b[38;5;241m=\u001b[39mscale,\n\u001b[0;32m   2049\u001b[0m         save\u001b[38;5;241m=\u001b[39msave,\n\u001b[0;32m   2050\u001b[0m         fold\u001b[38;5;241m=\u001b[39mfold,\n\u001b[0;32m   2051\u001b[0m         fit_kwargs\u001b[38;5;241m=\u001b[39mfit_kwargs,\n\u001b[0;32m   2052\u001b[0m         plot_kwargs\u001b[38;5;241m=\u001b[39mplot_kwargs,\n\u001b[0;32m   2053\u001b[0m         groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m   2054\u001b[0m         feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[0;32m   2055\u001b[0m         label\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[0;32m   2056\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2057\u001b[0m         display_format\u001b[38;5;241m=\u001b[39mdisplay_format,\n\u001b[0;32m   2058\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pycaret\\internal\\pycaret_experiment\\tabular_experiment.py:411\u001b[0m, in \u001b[0;36m_TabularExperiment._plot_model\u001b[1;34m(self, estimator, plot, scale, save, fold, fit_kwargs, plot_kwargs, groups, feature_name, label, verbose, system, display, display_format)\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    407\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEstimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not have the required fit() method.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    408\u001b[0m     )\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_available_plots:\n\u001b[1;32m--> 411\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlot Not Available. Please see docstring for list of available Plots.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# checking display_format parameter\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_model_check_display_format_(display_format\u001b[38;5;241m=\u001b[39mdisplay_format)\n",
      "\u001b[1;31mValueError\u001b[0m: Plot Not Available. Please see docstring for list of available Plots."
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "\n",
    "registered_model_name = 'model_kobe'\n",
    "nexamples = 5\n",
    "model_version = -1\n",
    "models = ['lr','dt']\n",
    "\n",
    "\n",
    "with mlflow.start_run(experiment_id=experiment_id, run_name = 'Treinamento'):\n",
    "  \n",
    "    exp = pc.setup(\n",
    "        data=xtrain,\n",
    "        target = 'shot_made_flag',\n",
    "        fold_strategy = 'stratifiedkfold',\n",
    "        test_data = xtest,\n",
    "        normalize=True,\n",
    "        log_experiment = False\n",
    "    )\n",
    "    list_models = pc.compare_models(['lr','dt'], n_select=2, sort='f1')\n",
    "\n",
    "    for plot_type in ['lr','dt']:\n",
    "        print('=> Aplicando ', plot_type)\n",
    "        artifact = pc.plot_model(list_models[0], plot=plot_type, save=True)\n",
    "        mlflow.log_artifact(artifact)\n",
    "\n",
    "\n",
    "    # REGRESSAO\n",
    "    exp.plot_model(list_models[0], plot='vc', save = True)\n",
    "    yhat_test = exp.predict_model(list_models[0])\n",
    "    plot_parameter_validation_curve(xtrain.drop('shot_made_flag', axis=1), ytrain, 'C', {'C': [0.001, 0.01, 0.1, 1, 10]},\n",
    "                                        list_models[0], 'Regressão Logística', 'f1', logx=False)\n",
    "    plt.savefig('lr_validation_curve.png')\n",
    "    mlflow.log_artifact('lr_validation_curve.png')\n",
    "    # os.remove('lr_validation_curve.png')\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        'lr_log_loss': log_loss(yhat_test.target, yhat_test.prediction_label),\n",
    "        'lr_f1': f1_score(yhat_test.target, yhat_test.prediction_label),\n",
    "    })\n",
    "    \n",
    "    # ARVORE\n",
    "    yhat_test = exp.predict_model(list_models[1])\n",
    "    plot_parameter_validation_curve(xtrain.drop('shot_made_flag', axis=1), ytrain, 'max_depth', {'max_depth': [2, 3, 4, 5, 6, 7, 8]},\n",
    "                                    list_models[1], 'Árvore Decisão', 'f1', logx=False)\n",
    "    plt.savefig('dt_validation_curve.png')\n",
    "    mlflow.log_artifact('dt_validation_curve.png')\n",
    "    # os.remove('dt_validation_curve.png')\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        'dt_log_loss': log_loss(yhat_test.target, yhat_test.prediction_label),\n",
    "        'dt_f1': f1_score(yhat_test.target, yhat_test.prediction_label),\n",
    "    })\n",
    "    \n",
    "     # FINALIZACAO MELHOR MODELO\n",
    "    tune_model = exp.tune_model(list_models[0],\n",
    "                                optimize = 'f1',\n",
    "                                search_library = 'scikit-learn',\n",
    "                                search_algorithm = 'random',\n",
    "                                n_iter = 4)\n",
    "    yhat_test = exp.predict_model(tune_model, raw_score=True)\n",
    "\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        'final_model_log_loss': log_loss(yhat_test.target, yhat_test.prediction_label),\n",
    "        'final_model_f1': f1_score(yhat_test.target, yhat_test.prediction_label),\n",
    "    })\n",
    "    yhat_test.to_parquet('../data/processed/prediction_test.parquet')\n",
    "    mlflow.log_artifact('../data/processed/prediction_test.parquet')\n",
    "    \n",
    "    final_model = exp.finalize_model(tune_model)\n",
    "\n",
    "    artifact = pc.plot_model(final_model, plot=plot_type, save=True)\n",
    "    mlflow.log_artifact(artifact)\n",
    "    \n",
    "    # EXPORTACAO PARA LOG E REGISTRO DO MODELO\n",
    "    exp.save_model(final_model, f'./{registered_model_name}') \n",
    "    # Carrega novamente o pipeline + bestmodel\n",
    "    model_pipe = exp.load_model(f'./{registered_model_name}')\n",
    "    # Assinatura do Modelo Inferida pelo MLFlow\n",
    "    model_features = list(xtrain.drop('shot_made_flag', axis=1).columns)\n",
    "    inf_signature = infer_signature(xtrain[model_features], \n",
    "                                    model_pipe.predict_proba(xtrain.drop('target', axis=1)))\n",
    "    # Exemplo de entrada para o MLmodel\n",
    "    input_example = {x: xtrain[x].values[:nexamples] for x in model_features}\n",
    "    # Log do pipeline de modelagem do sklearn e registrar como uma nova versao\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=model_pipe,\n",
    "        artifact_path=\"sklearn-model\",\n",
    "        registered_model_name=registered_model_name,\n",
    "        signature = inf_signature,\n",
    "        input_example = input_example,\n",
    "        pyfunc_predict_fn='predict_proba'\n",
    "    )\n",
    "    # Criacao do cliente do servico MLFlow e atualizacao versao modelo\n",
    "    client = MlflowClient()\n",
    "    if model_version == -1:\n",
    "        model_version = client.get_latest_versions(registered_model_name)[-1].version\n",
    "    # Registrar o modelo como staging\n",
    "    client.set_registered_model_alias(\n",
    "        name    = registered_model_name, \n",
    "        alias   = \"staging\", \n",
    "        version = model_version\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447fb4b0-81db-45a5-9acf-a4c02e410140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
